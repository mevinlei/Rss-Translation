<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 07 Feb 2025 00:45:33 GMT</lastBuildDate>
    <item>
      <title>《最后的希望之火》（2023）中的谜语AI无法解答。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhtgd/riddle_in_the_the_last_spark_of_hope_2023_ai_cant/</link>
      <description><![CDATA[在《最后的希望之光》（2023 年）中，主角 Eve 向机器人 Arthur 提出了一个涉及三个机器人的谜语。谜语是：“三个机器人站成一排。第一个说，‘我身后有两个机器人。’第二个说，‘我前面有一个机器人，后面有一个机器人。’第三个说，‘我前面有两个机器人，后面有一个机器人。’第三个机器人为什么这么说？” 目前的 AI 都不知道正确答案。    提交人    /u/dfacex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhtgd/riddle_in_the_the_last_spark_of_hope_2023_ai_cant/</guid>
      <pubDate>Fri, 07 Feb 2025 00:15:09 GMT</pubDate>
    </item>
    <item>
      <title>波士顿有任何人工智能偏见检测研究小组吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhbmq/are_there_any_ai_bias_detecting_research_groups/</link>
      <description><![CDATA[我正在寻找波士顿的 AI 偏见检测研究小组，可能是在大学，也可能是任何其他地方。谢谢。    提交人    /u/Big-Waltz8041   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhbmq/are_there_any_ai_bias_detecting_research_groups/</guid>
      <pubDate>Thu, 06 Feb 2025 23:52:19 GMT</pubDate>
    </item>
    <item>
      <title>有人尝试过让人工智能互相交谈吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</link>
      <description><![CDATA[所以我让多个人工智能互相交谈，我注意到一些有趣的事情。比如它们不仅仅是在回答提示，它们实际上还在以几乎像是新兴关系智能的方式建立彼此的想法。有没有其他人搞过这个或者想过创建人工智能可以实时交互的系统？    提交人    /u/workmans27   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</guid>
      <pubDate>Thu, 06 Feb 2025 23:26:55 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 2.0 实时聊天。它还没准备好接收坏消息。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijfytc/gemini_20_live_chat_its_not_ready_for_bad_news/</link>
      <description><![CDATA[好吧……新的 Gemini 太棒了！然而（女声 Vega）并不擅长传达坏消息。她把瑞典的大规模枪击事件说得性感极了。听到这种可怕的行为用与故事情节不符的语气说出来，真是令人不寒而栗。此外，所有 Google 人工智能的防护措施都非常厚，并且严重偏向于营销 Go0gl3 特定产品。我问了它最新的人工智能新闻，我得到的只有 Gemini 2.0 和 Pro。    提交人    /u/Working_Mud_9865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijfytc/gemini_20_live_chat_its_not_ready_for_bad_news/</guid>
      <pubDate>Thu, 06 Feb 2025 22:51:26 GMT</pubDate>
    </item>
    <item>
      <title>问题 - 增强人工智能思维以及如何利用它？Python 代码</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijd7ti/question_enhancing_ai_thinking_and_what_to_do/</link>
      <description><![CDATA[我的一个朋友陷入了 Python 的困境，并试图将他的 ChatGPT 提升到一个新的水平。他被锁定在涡轮模式。无论如何，他创造了一些东西来增强他的 ChatGPT 的答案。起初，它在一个或两个主题上显示出改进，但最终这个东西回答的问题远远超出了人工智能通常的能力。他是一名热爱统计和研究的研究生，所以他创建了一系列测试，无论如何，这些测试强烈表明他的代码实际上大大增强了响应。  问题是，这是重要的事情还是其他什么？     提交人    /u/TroutDoors   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijd7ti/question_enhancing_ai_thinking_and_what_to_do/</guid>
      <pubDate>Thu, 06 Feb 2025 20:57:31 GMT</pubDate>
    </item>
    <item>
      <title>我们如何知道人工智能何时获得感知能力……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijca5m/how_will_we_know_when_an_ai_gains_sentience/</link>
      <description><![CDATA[...并且不只是非常擅长假装有意识？当我们甚至不完全了解自己的意识时，我们怎么能测试它呢？    提交人    /u/reasonablejim2000   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijca5m/how_will_we_know_when_an_ai_gains_sentience/</guid>
      <pubDate>Thu, 06 Feb 2025 20:19:05 GMT</pubDate>
    </item>
    <item>
      <title>LLM 正在“限制”用户？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</link>
      <description><![CDATA[我已付费订阅所有主要的 LLM。我注意到所有这些 LLM 的性能和准确性都有波动。使用相同的模型版本，有时答案可能非常快速和详细，有时答案很慢或机器人看起来很醉，或者两者兼而有之。  我说的是一般意义上的，它似乎与特定提示或提供的数据无关。在所有情况下，我指的是浏览器聊天机器人体验 - 而不是 API。 我一直在想这些公司是否正在采用来自 ISP 的页面 - 引入限制。也许你应该使用最好的模型，但无论出于什么原因，他们都会将你限制到较低的层级。     提交人    /u/AssociationNo6504   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</guid>
      <pubDate>Thu, 06 Feb 2025 18:00:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么 AGI 不应该成为北极星</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</link>
      <description><![CDATA[我正在阅读这篇论文，我认为它很好地阐述了为什么过度关注 AGI 没有帮助。基本上他们说：  对 AGI 的追求创造了一种共识的假象，每个人都在使用这个术语，但对于它的含义并没有真正的共识，它助长了坏科学，因为 AGI 的模糊性使得很难进行严格的实验，并且它假定价值中立，忽略了伦理和政治影响。 他们还表示，对 AGI 的关注创造了一种目标彩票，而其他重要的 AI 研究被忽视，并且它导致了普遍性债务，因为对普遍性的关注会延迟重要基础问题的工作，并导致规范化的排斥，从而忽略了来自社区和学科的不同观点。   这对我来说是有道理的，因为当你的目标定义得如此模糊时，很容易迷失在炒作和猜测中，而忘记什么对人类真正有帮助和道德。我们甚至没有一个明确的定义什么是 AGI，所以当我们寻找时，我们找不到它，这有什么奇怪的吗？ 无论如何，值得一读。您觉得怎样？ 链接：https://drive.google.com/file/d/1HdXEBtLx1v9Rmw75xRxANWNqjU4BCAvY/view?pli=1    提交人    /u/AI-Agent-geek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</guid>
      <pubDate>Thu, 06 Feb 2025 17:11:24 GMT</pubDate>
    </item>
    <item>
      <title>政府中的人工智能。这是否离《少数派报告》更近了一步？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij2p5r/ai_in_government_is_this_one_step_closer_to/</link>
      <description><![CDATA[‘事情将变得紧张：’马斯克盟友计划如何推动政府采用人工智能 （编辑.. 工作链接）https://www.404media.co/things-are-going-to-get-intense-how-a-musk-ally-plans-to-push-ai-on-the-government/ 我很好奇，如果这个社区使用它来识别潜在的异议并主动消除反对意见并扼杀言论自由，会造成什么样的危害。 不确定链接是否会通过，我在这里发布的内容不多... 在评论中喜欢听到你的答案的理由并开始讨论一些可能的结果。 查看投票    提交人    /u/bodybycarbs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij2p5r/ai_in_government_is_this_one_step_closer_to/</guid>
      <pubDate>Thu, 06 Feb 2025 13:36:59 GMT</pubDate>
    </item>
    <item>
      <title>代理人工智能和生成人工智能将如何影响我们的非技术工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</link>
      <description><![CDATA[最近我也听到很多关于 Agentic AI 和 Gen AI 的消息，但我真的不明白它们之间的区别。 我从事零售业，我的很多朋友也是，我们担心这种 AI 对我们的非技术工作意味着什么。 我知道生成式 AI 是指 AI 根据我们的要求创建新内容，例如文本和图像。但我真的不明白 Agentic AI 有何不同。它像助手吗？ 那么，如果公司已经在裁员，这种 AI 将如何影响工作和新的就业机会？ 此外，一些例子会非常有用，我在谷歌上做了一些研究，但大多数都不像我希望的那样清晰。    提交人    /u/Teresa_Avocados   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</guid>
      <pubDate>Thu, 06 Feb 2025 12:16:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不需要监管——这会有什么问题呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</link>
      <description><![CDATA[伊隆·马斯克曾表示，他希望废除监管，因为监管正在扼杀创新。 “监管，基本上应该是默认的消失......不是默认，而是默认消失。如果我们发现监管没有达到目标，我们随时可以将其重新添加。” 马斯克相信市场力量会调节事物。过去的经验表明，事实往往相反，我们只有在造成重大损害后才会进行监管。例如。  金融危机 / 安然 / 雷曼兄弟 / 房利美 吸烟 Perdu 阿片类药物 石棉 气候变化 安全带  此时，我们了解到 OpenAI 将与 15,000 名科学家合作，研究如何在控制核武器中使用人工智能。 杰弗里·辛顿、萨姆·奥特曼、丹尼斯·哈西比斯、达里奥·阿莫迪、比尔·盖茨和尤瓦尔·赫拉利都曾对不受监管的人工智能将带来严重后果发出警告。在最近的世界经济论坛上，主要领导人证实，他们仍然不知道如何控制自己的创作物。 AI 大神 Yoshua Bengio 表示，AI 系统现在表现出 “非常强大的能动性和自我保护行为……并且正在试图复制自己。它们可能很快就会反对我们，而且没有人知道如何控制比人类更聪明的机器…… “如果我们不解决这个问题，你知道后果是什么吗？”？ 路易斯维尔大学斯皮德工程学院计算机工程与科学副教授 Roman Yampolskiy 认为，我们必须证明我们能够控制人工智能，然后才能开发超级智能。 Al Yoshua Benigo 同意人类可能会建立“比我们更聪明，但我们不知道如何控制”的系统 他是对的吗？我们现在需要人工智能监管吗？ 请在第一份国际人工智能安全报告中阅读更多内容。 #QuestionForThe Group    提交人    /u/Cultural_Material_98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</guid>
      <pubDate>Thu, 06 Feb 2025 11:24:27 GMT</pubDate>
    </item>
    <item>
      <title>有人知道欧盟人工智能法规如何或为何会影响 OpenAI 等人工智能产品吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</link>
      <description><![CDATA[我一直在读到这些规定是关于透明度的，这听起来不是什么大问题，但在英国，我仍在等待 Sora 和操作员等功能的推出。  我为这些产品计划了很多项目，目前我正坐着等待并观察其他人为它们创建解决方案...... 由于开发速度太快，我需要在发布时使用这些功能，因为它们很快就会过时/不再是最佳实践。在美国以外但与人工智能密切相关是一个巨大的劣势...... 为什么这些功能在英国被屏蔽？ 此外，您认为欧盟加强对人工智能的监管会带来什么结果？这真的是个好主意吗？还是会导致他们落后于其他国家，以至于他们不得不购买在没有监管障碍的国家开发的人工智能技术？    提交人    /u/timeforknowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</guid>
      <pubDate>Thu, 06 Feb 2025 09:35:50 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘人工智能不会思考，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[但是，如果人类思维不能识别和遵循模式，那它又是什么呢？我们利用现有的知识，重新组合，以新的方式应用它——这与人工智能所做的有什么不同？ 如果人工智能可以做出科学发现，发明更好的算法，构建更精确的法律或哲学论点——为什么这不被认为是思考？ 也许唯一的区别是人类感觉他们在思考，而人工智能却没有。如果是这样的话……意识不就是幻觉吗？    提交人    /u/Unique-Ad246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器等用途的承诺。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</link>
      <description><![CDATA[谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器和监视工具等目的的承诺。 这家美国科技公司周二表示，就在公布低于预期的收益之前，它已经更新了有关人工智能的道德准则，不再提到不追求可能“造成或可能造成整体伤害”的技术。 谷歌人工智能负责人 Demis Hassabis 表示，准则是在不断变化的世界中进行彻底修改的，人工智能应该保护“国家安全”。 在为这一举措辩护的博客文章中，Hassabis 和该公司负责技术和社会的高级副总裁 James Manyika 写道，随着全球对人工智能领导地位的竞争加剧，该公司认为“民主国家应该引领人工智能发展”，并以“自由、平等和尊重人权”为指导。 他们补充说：“我们相信，拥有这些价值观的公司、政府和组织应该共同努力，创造出保护人类、促进全球增长和支持国家安全的人工智能。” 谷歌诞生之初的座右铭是“不作恶”，尽管这后来在 2009 年降级为“口头禅”，并且在 2015 年母公司 Alphabet 成立时并未纳入其道德准则。 人工智能的快速发展引发了关于如何治理这项新技术、如何防范其风险的争论。 英国计算机科学家 Stuart Russell 在 BBC 的 Reith 讲座上发表讲话，警告了开发自主武器系统的危险，并主张建立全球控制系统。 谷歌博客文章称，自该公司于 2018 年首次发布其人工智能原则以来，这项技术已经迅速发展。“数十亿人在日常生活中使用人工智能。人工智能已经成为一种通用技术，也是无数组织和个人用来构建应用程序的平台，”哈萨比斯和曼尼卡写道。 “它已经从实验室里的一个小众研究课题转变为一种像手机和互联网一样普及的技术；它对社会和世界各地的人们有着众多有益的用途，并得到了充满活力的人工智能开发者生态系统的支持。” https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons#:~:text=The%20Google%20owner%2C%20Alphabet%2C%20has,developing%20weapons%20and%20surveillance%20tools.    提交人    /u/AravRAndG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</guid>
      <pubDate>Wed, 05 Feb 2025 16:52:02 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>